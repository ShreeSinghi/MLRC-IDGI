{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.io import read_image\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import gc\n",
    "\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\singh/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load(\"pytorch/vision:v0.10.0\", \"mobilenet_v2\", pretrained=True).cuda()\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "BLACK  = np.zeros((3, 224, 224))\n",
    "BLACK[0] -= 0.485\n",
    "BLACK[1] -= 0.456\n",
    "BLACK[2] -= 0.406\n",
    "BLACK = BLACK[None] # adds extra first dimension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def straight_path_images(model, images, n_steps):\n",
    "\n",
    "    x_diff = images - BLACK\n",
    "    path_images = []\n",
    "    \n",
    "    for alpha in np.linspace(0, 1, n_steps):\n",
    "        x_step = BLACK + alpha * x_diff\n",
    "        path_images.append(x_step)\n",
    "    \n",
    "    path_images = torch.Tensor(path_images).transpose(0, 1)\n",
    "\n",
    "    # returns x sequence\n",
    "    return path_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [preprocess(Image.open(\"doberman.png\"))]*2\n",
    "sequence = straight_path_images(model, images, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200\n",
      " 200 200 236 236 236 236 236 236 236 236 236 236 236 236 236 236 236 236\n",
      " 236 236 236 236]\n",
      "torch.Size([40])\n",
      "torch.Size([2, 20, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "def IG(model, sequence, class_idxs):\n",
    "    model.eval()\n",
    "    sequence = sequence.cuda()\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False \n",
    "\n",
    "    sequence.requires_grad = True\n",
    "    classes = np.repeat(class_idxs, sequence.shape[1])\n",
    "\n",
    "    output = model(sequence.reshape((-1,)+sequence.shape[2:]))\n",
    "    output = output[np.arange(output.shape[0]), classes]  # index that particular class for each image\n",
    "    \n",
    "    gradient = torch.ones_like(output)\n",
    "    \n",
    "    model.zero_grad()\n",
    "    output.backward(gradient)\n",
    "    \n",
    "    gradient = sequence.grad.view(sequence.shape).detach()\n",
    "\n",
    "    return (gradient.sum(1) * (sequence[:,1]-sequence[:,0]).detach()).abs().mean(1).cpu()\n",
    "            \n",
    "\n",
    "saliency = IG(model, sequence, class_idxs=[200,236])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
